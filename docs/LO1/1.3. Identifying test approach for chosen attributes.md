# Functional Tests
Functional tests make up most of the testing stack, namely in the ensuring the database handles user inputs correctly. These tests ensure the simple function of adding the items to the database has worked, via the means of subsequent retrieval. We extend this with *Fault-Based Testing*, which ensures the database not only doesn't add malformed or missing-attribute data, but also informs us adequately.

# Statistical Testing
Statistical Tests cover our performance metrics. We can use tools (such as those built into Chrome itself, for example) to measure our extension's impact on the DOM. Additionally, tools (such as *[YCSB](https://en.wikipedia.org/wiki/YCSB)*) can be used to test hypothetical future scenarios where the database would be under heavy load from multiple simultaneous reads.
# Integration tests
Integration tests would likely require the usage of debug logging and messages to test the simple "linking" of database and extension; it would also be beneficial to have the extension load data from the database to test this too. We should also ensure the extension's "URL submission" functionality integrates correctly with the database (this will also require some form of functional testing as mentioned above).
## Data Flow Testing
Since the "highest level" of item is a "*Media*" entry, we could track this item's interactions through our entire testing suite to see when and how it was interacted with (involving being queried by the database and the extension)
# System-Level Tests
Database analysis to ensure each item fits with the schema, but mainly testing here might be best manually; sitting a regular user down and seeing how they handle adding a media item, getting URLs for spoilers, etc - this will show how accessible the extension (and software) is.